
# 概要

AI事故における対外説明の要諦は、AIを「ブラックボックス」として逃げ道にするのではなく、**「人間が管理するシステムの一部が、どう失敗したか」** を透明性を持って語ることです。経営層と法務が握るべき「説明の型」を整理します。

# 1. 【道（Why）：目的】「隠蔽」を捨て「誠実な情報開示」を武器にする

* **行動指針：** 「原因がわかるまで黙る」のは、現代のSNS時代においては「地」を失う行為です。
* **対外メッセージの核：** 
	- 1. 異常の検知事実（何を把握したか）
	* 2. 直後にとったアクション（即時停止したこと：将の判断）
	* 3. 影響範囲と今後の救済策

> **情報の空白は、憶測という名の「敵」を呼び込む。**

# 2. 【将（Who）：責任】「AIのせい」を法的に封印する

* **法務的定義：** 「AIが勝手に判断した」というロジックは、製造物責任や善管注意義務の観点から通用しません。
* **責任の所在：** 「AIの出力」を「組織の意思決定」として採用した時点での、**人間側の確認プロセス（法）の不備**として整理します。
* これにより、「制御不能な魔物」を野放しにしていたのではなく、「不完全な道具の運用ミス」として、再発防止策を論理的に提示可能になります。

# 3. 【法（How）：規律】「停止・再開」の法的エビデンスを保全する

* **証拠保全：** 事故発生時の入力データ（地）、AIの出力、および「将（責任者）」が停止ボタンを押した時間のログを完全保全します。
* **説明責任の完遂：**  -
	* 「なぜ止めたのか（安全優先の判断）」
	* 「なぜ再開できると判断したのか（五事の再検証）」
	* このプロセスを記録しておくことが、法的紛争時における最大の防御となります。


# 4. 対外リリース構成のテンプレート（三段構成）

| 構成要素      | 孫子のエッセンス          | 具体的な記述内容                         |
| --------- | ----------------- | -------------------------------- |
| **即時開示**  | **其の疾きこと風のごとく**   | 異常検知から◯分以内に「調査中」および「システム停止」を公表。  |
| **中間報告**  | **其の静かなること林のごとく** | 判明した事実（地）のみを淡々と述べ、不確かな憶測を排除。     |
| **再発防止策** | **動かざること山ののごとし**  | 体制（将）と運用（法）をどう変えたか、揺るぎない再設計案を提示。 |

# SAのアドバイス

経営・法務にとっての「勝ち」とは、裁判に勝つことではなく、**「事故の後でも、顧客がそのサービスを使い続けてくれること」**です。

* **AIを擬人化しない：** 「AIが嘘をつきました」ではなく「推論プロセスのガードレールが機能しませんでした」と技術的に、かつ責任の所在（人間）を明確にして語ってください。
* **撤退の迅速さを誇る：** 「止めるのが遅れたこと」を謝罪するのではなく、「被害を最小限に抑えるために即断即決で止めたこと」を組織の健全性としてアピールしましょう。

> **「不敗の組織」とは、事故を起こさない組織ではなく、**
> **事故に直面した際、最も誠実かつ迅速に「法」を執行できる組織のことです。**

>「SAとは、システムアナリスト（Systems Analyst）またはシステムアーキテクト（System Architect）。
