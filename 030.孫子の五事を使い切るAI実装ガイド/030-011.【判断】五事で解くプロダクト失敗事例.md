
# 概要

AIプロダクトが市場や現場で「死」を迎える原因を解剖すると、そのほとんどが技術的な問題ではなく、導入前の「判断（計）」の欠落にあります。五事のフィルターを通過できなかったプロダクトがどのような末路を辿るのか、その典型パターンを整理します。

# 五事から読み解くAIプロダクトの死因

### 1. 【道｜Why】目的の欠如：迷走する「おもちゃ」

* **失敗パターン：** 「AIを使って何かすごいことをしろ」という上層部からのトップダウンに対し、解くべき業務課題が曖昧なまま開発を強行。
* **結末：** デモ映えはするが、実務上のKPI（コスト削減や売上向上）に寄与せず、**「面白いが、いらない」** と判断されて死蔵されます。
* **孫子の視点：** 目的（道）なき軍は、どれほど武装が厚くても、進むべき方向を見失い自滅します。

### 2. 【将｜Who】責任の不在：誰も守らない「孤児」

* **失敗パターン：** AIが誤ったアウトプットを出した際、誰がそれを修正し、誰が顧客に謝罪し、誰がシステムを止めるのかが決まっていない。
* **結末：** 誤判断が一度起きただけで現場がパニックになり、**「リスクが大きすぎる」** として機能をオフにされ、二度と使われません。
* **孫子の視点：** 将（リーダー）が責任を引き受けない戦場では、兵（システム）への信頼が瞬時に崩壊します。

### 3. 【天｜When】機微の読み違え：早すぎた「遺作」

* **失敗パターン：** LLMのトークン単価が極めて高い時期に、薄利多売のサービスに組み込んだり、法的規制が不透明な領域へ無理に参入したりする。
* **結末：** プロダクトが成長するほど赤字が膨らみ、あるいは**法改正によってサービス継続が不可能**になり、志半ばで撤退を余儀なくされます。
* **孫子の視点：** 天時（時流）を無視した進軍は、兵力の枯渇を招くだけの無謀な戦いです。

### 4. 【地｜Where】環境の不適合：泥沼の「PoC止まり」

* **失敗パターン：** 学習データが著しく汚い、あるいは現場のオペレーションがアナログすぎてAIを組み込む余地がないことを軽視。
* **結末：** 開発環境では動くが、本番環境（現場）では精度が出ず、**「いつまで経っても本番化できない」** という泥沼のPoCを繰り返します。
* **孫子の視点：** 地形（現場・データ）を知らずに進軍する者は、伏兵（データの不備）に遭って必ず敗北します。

### 5. 【法｜How】運用の欠陥：制御不能な「事故製造機」

* **失敗パターン：** 100%の精度を信じ込み、人間によるチェックプロセス（HITL）や異常検知の仕組みを疎かにしたまま全自動化。
* **結末：** 誤情報（ハルシネーション）を外部に垂れ流して炎上し、**ブランドイメージに致命的なダメージ**を負って強制終了します。
* **孫子の視点：** 規律（法）なき攻撃は、自軍を焼き尽くす「制御できない火」と同じです。

# 最も致命的な「失敗の掛け合わせ」

* **道（Why）× 地（Where）：** 「何のために（道）」と「どこで（地）」がズレており、誰にも望まれないものが作られる。
* **将（Who）× 法（How）：** 責任者（将）がおらず、止める仕組み（法）もない。事故が起きるべくして起きる状態。

# 一文まとめ

> **AIプロダクトの失敗原因は、**
> **モデルの性能不足ではなく、常に「五事」のいずれかの欠落にある。**
