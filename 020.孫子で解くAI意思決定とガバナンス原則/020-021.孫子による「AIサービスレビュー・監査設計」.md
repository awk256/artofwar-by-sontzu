
# 概要

AIプロジェクトのレビューにおいて、技術的な精度（LTVやF値）だけに目を奪われるのは危険です。孫子の五事を用いることで、サービスを「社会（あるいは本番環境）にデプロイしてよいか」を多角的に評価する**監査フレームワーク**が完成します。

>LTV（顧客生涯価値）とF値（購入頻度）は、主にEC・サブスクリプションビジネスにおいて、安定した売上成長を目指すために不可欠なマーケティング指標。 
>F値（Frequency）はRFM分析（顧客分析手法）の一部であり、LTVの主要な構成要素として機能する。

# 五事 × AIサービスレビュー／監査基準

### 1. 道（Why）｜ 目的監査

* **確認事項：** AIの利用目的が「特定の業務解決」に限定され、明文化されているか。その目的は社会倫理に照らして正当か。
* **NG判定の例：** 「何かに使えそうだから」といった汎用的な目的、あるいは改善すべきKPIが定義されていないプロジェクト。

> **監査の急所：** 「目的不明なAI」は、予期せぬ挙動をした際に、それが「異常」かどうかの判断すらできません。

### 2. 将（Who）｜ 責任監査

* **確認事項：** AIのアウトプットに対して最終責任を負う「人間」が個人名レベルで特定されているか。
* **NG判定の例：** 「AI委員会が責任を持つ」「ベンダーの仕様です」といった、責任の所在が霧散している状態。

> **監査の急所：** 責任不在のAIは、事故発生時に必ず「なすりつけ合い」を招き、組織の信頼を失墜させます。

### 3. 天（When）｜ 妥当性監査

* **確認事項：** モデルの精度、推論コスト、および現在の法規制や社会的な受容性が「今」の導入を肯定しているか。
* **NG判定の例：** 精度検証が限定的なPoCに留まっている、または将来的な法規制（AI法等）への適合計画がない。

> **監査の急所：** 技術的に可能であっても、社会が受け入れる「時（天）」が来ていなければ、リリースはリスクでしかありません。

### 4. 地（Where）｜ 適合性監査

* **確認事項：** 学習データと本番データの乖離（ドリフト）がないか。現場のオペレーションにAIが「物理的に」組み込み可能か。
* **NG判定の例：** 現場の担当者がAIの介在を拒絶している、あるいは本番環境で必要なデータが恒常的に不足している。

> **監査の急所：** 「現場（地）」に適応しないAIは、どれほど高精度でも現場で無視され、死蔵されます。

### 5. 法（How）｜ 運用・安全監査

* **確認事項：** 人間が介入するプロセス（[Human-in-the-loop](https://www.google.com/search?q=020-032.md)）が設計されているか。緊急停止ボタンや、判断根拠を遡るログはあるか。
* **NG判定の例：** 人間のチェックを介さない全自動プロセス、および挙動の追跡が不可能なブラックボックス設計。

> **監査の急所：** **「止められないAI」**　は、兵法でいうところの「火攻めの自滅」と同じです。


# 一文まとめ

> **五事とは、**
> **AIサービスを「社会に出してよいか」を判断するための、**
> **最小かつ十分な監査軸である。**

この5つの関門を突破できないプロジェクトは、技術的にどれほど優れていても「戦略的に敗北している」と見なし、本番投入を差し止める勇気（勇）がレビューワーには求められます。
