
# 概要

現代、AI活用の成否は「精度」や「コスト」以上に、**「倫理的妥当性」** に左右されます。古典的な五事だけでは、ビジネスには勝てても、社会的信頼（Social License）を失うリスクがあります。本項では、五事に現代のAIガバナンス原則を「内蔵」させた新たな評価軸を提示します。

### 五事 × 倫理原則 統合マトリクス

孫子の五事をベースに、現代のAIサービスが満たすべき倫理的要件をマッピングしました。

| 軸       | 五事           | AIガバナンスの視点 | 統合すべき倫理原則                      |
| ------- | ------------ | ---------- | ------------------------------ |
| **目的**  | **道(Why)**   | 利用目的の限定    | **公益性・人間中心の便益**                |
| **責任**  | **将(Who)**   | 最終決定権・停止権限 | **説明責任（Accountability）・説明可能性** |
| **妥当性** | **天(When)**  | 技術成熟度・法規制  | **社会受容性・ロバストネス（安全性）**          |
| **適合性** | **地(Where)** | データ品質・現場適合 | **公平性・非差別（Bias Control）**      |
| **運用**  | **法(How)**   | 監視・停止・ログ管理 | **透明性・監査可能性（Auditability）**    |

---

# AIサービス向け「拡張五事」の定義

アーキテクトが設計・レビュー時に用いるべき、5つの拡張評価基準です。

### 1. 道（Why）＋ 公益：目的の正当性

* 単なる自社の利益（勝利）だけでなく、そのAIサービスが **「社会的に許容される目的」** で使われているか。
* アルゴリズムが人間の尊厳を損なう方向（依存性の強化や不当な監視など）に向いていないかを確認します。

### 2. 将（Who）＋ 説明責任：判断の透明性

* 孫子の「将」が持つ決断力に加え、**「なぜその判断をしたか」を人間が説明できること** を要件とします。
* AIのブラックボックス性に甘んじず、人間が最終的な責任を引き受けられる設計（Human-in-the-loop）を担保します。

### 3. 天（When）＋ 安全性：被害の局所化

* 導入のタイミング（天）を計る際、**「想定外の挙動が発生しても被害が限定的か」** という安全性を最優先します。
* 市場の盛り上がり（時勢）に流されず、技術的な脆弱性を無視した早期リリースを厳禁します。

### 4. 地（Where）＋ 公平性：バイアスの排除

* 特定のデータ群に最適化させる際、それが結果として特定のユーザー層や条件を不利に扱っていないかを検証します。
* データの偏りが生む「構造的な差別」を、地形の不利と同様に「避けるべきリスク」と定義します。

### 5. 法（How）＋ 透明性：検証可能性

* 運用の仕組み（法）には、**後から判断プロセスを検証し、必要に応じて即座に介入・停止できる機能**を含めます。
* ログの保全や外部監査への対応を、規律（法）の根幹に据えます。

### 一文まとめ

> **AI時代の五事とは、**
> **「勝てるか（Can we win?）」ではなく**
> **「使ってよいか（Should we use?）」を同時に判断するための枠組みである。**

この「拡張五事」こそが、AIという巨大な力を、自社を焼き尽くす「火」から、社会を照らす「光」へと変えるための設計指針となります。