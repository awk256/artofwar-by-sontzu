
### 結論

**孫子の兵法は、AIプロダクトを  
「安全に・長く・使われ続けるもの」にする設計原則になる。**

# 孫子 → AIプロダクト設計 原則対応

### 原則①｜戦わずして勝つ

**＝ AIで全部やらない**

- 人がやった方が速い・安全な部分は残す

- AIは「ボトルネックだけ」を担当

👉 _全自動化を目指すAIは短命_


### 原則②｜勝てない戦いはしない

**＝ 解けない問題にAIを使わない**

- データがない

- 評価できない

- 責任が持てない

👉 _解けない課題にAIを入れると信用を失う_


### 原則③｜負けない形を先に作る

**＝ ガードレール先行設計**

- 出力制限

- 人チェック

- 停止ボタン


👉 _精度より安全性を先に作る_


### 原則④｜状況に応じて変える

**＝ 固定AIにしない**

- モデル更新

- ルール切替

- 人介入率の調整


👉 _変えられないAIはすぐ陳腐化_


### 原則⑤｜情報を制する

**＝ データとログが命**

- 入力・出力を必ず残す

- 解釈可能性を確保


👉 _説明できないAIは捨てられる_


## AIプロダクト設計・孫子的まとめ

> **良いAIとは  
> 速いAIでも賢いAIでもなく  
> 「負けないAI」である**