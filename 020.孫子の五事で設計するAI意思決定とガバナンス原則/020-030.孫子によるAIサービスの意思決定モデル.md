
# 概要

AI導入の意思決定において、人間が解くべきは「戦略」であり、AIが解くべきは「最適化」です。本項では、孫子の思想を「判断・実行・制御」の3層に分離した意思決定モデルを提示します。

# 1. 総合意思決定アーキテクチャ

孫子の兵法を上位OSとし、人間が「土俵（フレーム）」を、AIが「推論」を担当する構造です。


```mermaid
graph TD
    subgraph "判断設計層（人）: 戦略OS"
        A[五事: 道・天・地・将・法] --> B{意思決定フレーム}
    end

    subgraph "最適化層（AI）: 実行エンジン"
        B --> C[高速推論 / 予測]
        C --> D[パターン認識]
    end

    subgraph "制御・安全層（人＋AI）: ガードレール"
        D --> E{異常検知 / 倫理フィルタ}
        E -- 異常 --> F[キルスイッチ/人への介入要求]
        E -- 正常 --> G[最終出力]
    end

    style A fill:#f9f,stroke:#333,stroke-width:2px
    style B fill:#f9f,stroke:#333,stroke-width:2px
    style C fill:#bbf,stroke:#333
    style D fill:#bbf,stroke:#333
    style E fill:#dfd,stroke:#333
    style F fill:#f66,stroke:#333
```

* **判断設計層（人）：** 「五事」に基づき、目的の正当性、リソースの妥当性、撤退基準を定義します。
* **最適化層（AI）：** 人間が定義した境界条件の中で、高速にパターン認識と予測を行います。
* **制御・安全層（人＋AI）：** 現代の「倫理原則」をパッチとして当て、異常検知時の停止や介入を司ります。

# 2. 【経営層向け】導入判断モデル

経営層が向き合うべきは、アルゴリズムの優劣ではなく **「リスクと責任のバランス」** です。

```mermaid
graph TD
    subgraph "経営判断の天秤"
        direction TB
        A[目的判断: 必然性はあるか?] --- B[責任判断: 組織で責任を取れるか?]
        B --- C[社会判断: レピュテーションリスク]
    end

    A & B & C --> D{最終決断}
    D -- GO --> E[現場へ権限委譲]
    D -- NO-GO --> F[代替案/不戦の選択]

    style D fill:#fff4dd,stroke:#d4a017,stroke-width:4px
    style E fill:#d4edda,stroke:#28a745
    style F fill:#f8d7da,stroke:#dc3545
```

* **目的判断：** なぜAIなのか？ 代替手段（人や既存システム）で「戦わずして勝つ」道はないか。
* **責任判断：** AIが誤った際、その社会的・経済的責任を組織として引き受けられるか。
* **社会判断：** 公益性はあるか。事故が起きた際のレピュテーションリスクに耐えられるか。

> **経営判断の鉄則：**
> **技術の詳細は見ない。「目的の正しさ」と「責任の所在」の2点のみでGO/NO-GOを決する。**


# 3. 【現場向け】設計・運用モデル

現場のエンジニアやSAが死守すべきは、**「不敗の形（堅牢な運用）」**です。

```mermaid
graph TD
    subgraph "現場の不敗設計"
        M1[道: 開発の大義共有] --> M2[天・地: データと技術の適合評価]
        M2 --> M3[将: 最終判断者の定義]
        M3 --> M4[法: 運用ルールと制御設計]
    end

    M4 --> OP{実運用}
    OP -- 異常発生 --> KS[キルスイッチ発動]
    KS --> HITL[人間が介入/修正]
    HITL --> M1

    style M4 fill:#fff3cd,stroke:#ffc107,stroke-width:2px
    style KS fill:#ff4d4d,stroke:#333,color:#fff
```


* **道：** なぜこのAIを実装するのか、開発チーム内で「大義」を共有できているか。
* **天・地：** 今のデータセット（地）と、モデルの進化速度（天）は実運用に耐えうるか。
* **将：** 判断に迷った際、最終的に誰が「白黒」をつけるのか。
* **法：** **「止められるか？」** 異常時に人間が即座に介入できる「キルスイッチ」があるか。

> **現場設計の鉄則：**
> **「作れるか？」よりも「事故らずに運用できるか？」を優先する。運用設計が未完成のAIは、技術的に動いても「未完成」とみなす。**


# 一文まとめ

> **孫子は「AIに何をさせないか」の境界線を引く思想であり、**
> **AIはその安全な境界内で、能力を最大化する道具である。**

この役割分担を明確にすることで、経営層は「安心」して投資でき、現場は「確信」を持って開発に取り組むことが可能になります。
