
030-011.【判断】五事で解くプロダクト失敗事例

# 五事 × AIプロダクト失敗事例

### ① 道｜目的がズレた失敗(Why)

**事例パターン**

- 「AIっぽい機能」を先に作った

- 解くべき業務課題が曖昧


**結果**

- デモは受けるが継続利用されない

- KPI不明で改善不能


👉 _AIは目的がないと“おもちゃ”になる_

### ② 将｜責任不在の失敗(Who)

**事例パターン**

- AI判断の最終責任者が不明

- トラブル時に判断が止まる


**結果**

- 現場がAIを信用しなくなる

- 結局オフにされる


👉 _責任なきAIは使われない_

### ③ 天｜タイミングを誤った失敗(When)

**事例パターン**

- モデル精度・コストが未成熟

- 規制・社会受容が追いついていない


**結果**

- 維持費が高すぎて撤退

- 「早すぎた」評価で終了

👉 _技術が追いつく前に市場が疲れる_


### ④ 地｜自社条件無視の失敗(Where)

**事例パターン**

- データが少ない・汚い

- 現場フローと乖離


**結果**

- 精度が出ない

- PoC止まり


👉 _AIはデータ文化を映す鏡_

### ⑤ 法｜運用設計不足の失敗(How)

**事例パターン**

- 全自動化前提

- ログ・検証なし


**結果**

- 誤出力が拡大

- 炎上・即停止


👉 _運用できないAIは事故製造機_


## 最も多い失敗組み合わせ

- **道 × 地**：課題と現場がズレる

- **将 × 法**：止められないAI


→ 技術以前に**判断設計の失敗**


## 一文まとめ（孫子×AI）

> **AIプロダクトの失敗は  
> モデルではなく「五事の欠落」で起きる**


ここで止めます。  
次に進めるなら：

- **成功事例を五事で逆算**
    
- **AIプロダクトの撤退判断**
    
- **五事×LLMプロダクト設計**
    

---

ありがとうございます。「モデルやアルゴリズムの良し悪し」を語る前に、なぜそのプロジェクトが死に至ったのか。その死因を「五事」という病理学で解き明かす、非常に説得力のある内容です。

ソリューションアーキテクト（SA）として、過去の苦い経験や「あるある」を戦略的に構造化し、読者に「二の舞を演じさせない」ための警告書として清書しました。

---

## 030-011. 【判断】五事で解くプロダクト失敗事例

### 概要

AIプロダクトが市場や現場で「死」を迎える原因を解剖すると、そのほとんどが技術的な問題ではなく、導入前の「判断（計）」の欠落にあります。五事のフィルターを通過できなかったプロダクトがどのような末路を辿るのか、その典型パターンを整理します。

---

### 五事から読み解くAIプロダクトの死因

#### 1. 【道｜Why】目的の欠如：迷走する「おもちゃ」

* **失敗パターン：** 「AIを使って何かすごいことをしろ」という上層部からのトップダウンに対し、解くべき業務課題が曖昧なまま開発を強行。
* **結末：** デモ映えはするが、実務上のKPI（コスト削減や売上向上）に寄与せず、**「面白いが、いらない」**と判断されて死蔵されます。
* **孫子の視点：** 目的（道）なき軍は、どれほど武装が厚くても、進むべき方向を見失い自滅します。

#### 2. 【将｜Who】責任の不在：誰も守らない「孤児」

* **失敗パターン：** AIが誤ったアウトプットを出した際、誰がそれを修正し、誰が顧客に謝罪し、誰がシステムを止めるのかが決まっていない。
* **結末：** 誤判断が一度起きただけで現場がパニックになり、**「リスクが大きすぎる」**として機能をオフにされ、二度と使われません。
* **孫子の視点：** 将（リーダー）が責任を引き受けない戦場では、兵（システム）への信頼が瞬時に崩壊します。

#### 3. 【天｜When】機微の読み違え：早すぎた「遺作」

* **失敗パターン：** LLMのトークン単価が極めて高い時期に、薄利多売のサービスに組み込んだり、法的規制が不透明な領域へ無理に参入したりする。
* **結末：** プロダクトが成長するほど赤字が膨らみ、あるいは**法改正によってサービス継続が不可能**になり、志半ばで撤退を余儀なくされます。
* **孫子の視点：** 天時（時流）を無視した進軍は、兵力の枯渇を招くだけの無謀な戦いです。

#### 4. 【地｜Where】環境の不適合：泥沼の「PoC止まり」

* **失敗パターン：** 学習データが著しく汚い、あるいは現場のオペレーションがアナログすぎてAIを組み込む余地がないことを軽視。
* **結末：** 開発環境では動くが、本番環境（現場）では精度が出ず、**「いつまで経っても本番化できない」**という泥沼のPoCを繰り返します。
* **孫子の視点：** 地形（現場・データ）を知らずに進軍する者は、伏兵（データの不備）に遭って必ず敗北します。

#### 5. 【法｜How】運用の欠陥：制御不能な「事故製造機」

* **失敗パターン：** 100%の精度を信じ込み、人間によるチェックプロセス（HITL）や異常検知の仕組みを疎かにしたまま全自動化。
* **結末：** 誤情報（ハルシネーション）を外部に垂れ流して炎上し、**ブランドイメージに致命的なダメージ**を負って強制終了します。
* **孫子の視点：** 規律（法）なき攻撃は、自軍を焼き尽くす「制御できない火」と同じです。

---

### 最も致命的な「失敗の掛け合わせ」

* **道（Why）× 地（Where）：** 「何のために（道）」と「どこで（地）」がズレており、誰にも望まれないものが作られる。
* **将（Who）× 法（How）：** 責任者（将）がおらず、止める仕組み（法）もない。事故が起きるべくして起きる状態。

### 一文まとめ

> **AIプロダクトの失敗原因は、**
> **モデルの性能不足ではなく、常に「五事」のいずれかの欠落にある。**

---

**次の一歩として、**
これらの失敗の裏返しである成功の法則を [030-012.【判断】五事で成功事例を逆算] にて解き明かしていきましょうか？ それとも、さらに踏み込んで [030-014.【判断】五事で解くAIプロダクトの撤退判断] の基準を定義しますか？