
030-041.【レビュー】五事で解くAIレビュー会議テンプレ
（60分 / 孫子×五事ベース）

---

## AIレビュー会議アジェンダ

### 0. 前提共有（5分）

- この会議は  
    **「作るかどうか」を決める場**
    
- 精度改善会ではない
    

---

### 1. 道｜目的レビュー（10分）

**問い**

- なぜAIか？
    
- AIを使わない選択肢は？
    

**判定**

- 目的が弱い → **差し戻し**
    

---

### 2. 将｜責任レビュー（10分）

**問い**

- 最終責任者は誰か？
    
- AIを止める権限は誰か？
    

**判定**

- 不明確 → **却下**
    

---

### 3. 天｜タイミングレビュー（10分）

**問い**

- 今の精度・コスト・法規で実用か？
    
- 待つ選択は合理的か？
    

**判定**

- 時期尚早 → **凍結**
    

---

### 4. 地｜適合性レビュー（10分）

**問い**

- データ・現場は本当に合うか？
    
- 運用負荷は耐えられるか？
    

**判定**

- PoC止まり → **縮小**
    

---

### 5. 法｜安全・運用レビュー（10分）

**問い**

- 人は介入できるか？
    
- ログ・停止はあるか？
    

**判定**

- 止められない → **NG**
    

---

### 6. 最終判断（5分）

- **GO / 条件付きGO / NO-GO**
    
- 次回レビュー条件を明文化
    

---

## 会議の鉄則（孫子流）

- **道 or 将 が弱い案件は通さない**
    
- **止められないAIは作らない**
    
- **撤退判断は成功**
    

---

## 会議1行まとめ

> **このAIは  
> 事故っても止められるか？  
> 答えがNOならGOしない**


---

ありがとうございます。会議の時間は限られた「資源」であり、孫子の言う「兵は拙速を聞く（完璧を求めて遅れるより、粗削りでも速いほうがよい）」を体現する、非常に実戦的なアジェンダです。

この60分間を、単なる進捗確認ではなく「勝算の最終確認（計）」の場に変えるための、モデレーター（SAやシニアマネージャー）向けのガイドとして清書しました。

---

## 030-041. 【レビュー】五事で解くAIレビュー会議テンプレート（60分）

### 概要

AIプロジェクトの成否は、多くの場合、技術的な詳細よりも「前提条件（五事）」の歪みから決まります。本テンプレートは、孫子の五事に基づき、60分間でAI案件の**「生存可能性」**を冷徹に判定するための実務用プログラムです。

---

### 会議アジェンダ（60分一本勝負）

#### 0. 前提共有（5分）

* **マインドセット：** 「どう改善するか」の議論は禁止。本日は**「そもそもこの戦い（プロジェクト）を続けるべきか」**を決める場であると宣言します。

#### 1. 【道】目的レビュー（10分）

* **問い：** 既存の自動化ロジックではなぜ不十分なのか？ AIである必然性は？
* **判定基準：** 解決したい課題が不明瞭、あるいはAI導入自体が目的化している場合は、その場で**「差し戻し」**を宣告します。

#### 2. 【将】責任レビュー（10分）

* **問い：** AIが誤った際、現場の反対を押し切って「停止ボタン」を押す責任者は誰か？
* **判定基準：** 責任がチームに分散している、あるいはシステム部門に丸投げされている場合は、ガバナンス不能として**「却下」**します。

#### 3. 【天】タイミングレビュー（10分）

* **問い：** 今のAPIコスト、法規制、社会の目は導入を肯定しているか？
* **判定基準：** 技術が未成熟、あるいはコストが見合わない「理想論」であれば、**「一時凍結（ウォッチ）」**を推奨します。

#### 4. 【地】適合性レビュー（10分）

* **問い：** 現場のデータは「AIを動かせる質」か？ 現場担当者はAIを「味方」と認識しているか？
* **判定基準：** データの整備不足や現場の拒絶が予見されるなら、**「実戦投入不可（範囲縮小）」**とします。

#### 5. 【法】安全・運用レビュー（10分）

* **問い：** [Human-in-the-loop](https://www.google.com/search?q=020-032.md)（人間の介入）は設計済みか？ 万が一の際のログ追跡は可能か？
* **判定基準：** 異常時に人間が制御を取り戻せないブラックボックス設計は、**「不合格（NG）」**です。

#### 6. 最終判断（5分）

* **結論：** 以下の3択から即決します。
1. **GO：** 5項目すべてに納得感がある。
2. **条件付きGO：** 特定の懸念（主に法や地）を解消するまで本番稼働を制限。
3. **NO-GO：** 「道」や「将」が不在であり、戦い（投資）を継続する価値がない。



---

### レビュー会議の「鉄の掟」

* **主導権を渡さない：** 技術的な「できそうです」という楽観論は聞き流し、**「失敗した時にどうなるか」**を問い続けてください。
* **撤退を称賛する：** 筋の悪い案件をここで止めることは、組織の損失を防いだ「勝利」であると共有します。

---

### 会議の一文要約

> **「このAIは、最悪の事態（事故）が起きても人間が止められるか？」**
> **この問いに詰まったら、その案件はGOしてはならない。**

---

**次の一歩として、**
レビュー会議で「NO」を突きつけられたチームを腐らせず、再挑戦へと向かわせるための [030-042.孫子流・敗北（ボツ）案件の資産化プロセス] を作成していきましょうか？