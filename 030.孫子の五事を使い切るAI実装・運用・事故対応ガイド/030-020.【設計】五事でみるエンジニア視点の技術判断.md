
了解です。  
**第1段階：既存内容を「AI × 五事（エンジニア視点）」に再構成**します。  
※構造は維持し、**AI特有の判断軸**を追加しています。

---

## ① 道（Why｜AIを使う理由が共有されているか）

### AI的観点

- **なぜAIなのか**（ルール・自動化ではダメか）
    
- 人の判断を**どこまで置き換える／補助する**のか明確か
    

### 失敗例

- 「AIを入れたい」から始まる設計
    
- LLM導入が目的化したプロダクト
    

👉 _AIは目的ではない。判断コスト削減の手段_

---

## ② 天（タイミング｜AIとして今か）

### AI的観点

- モデル精度・コストは**実用域**か
    
- API・モデル更新頻度に**耐えられる設計**か
    

### 失敗例

- 精度前提が甘いまま本番投入
    
- モデル変更で挙動が壊れる
    

👉 _早すぎるAIはPoCで終わる_

---

## ③ 地（戦場＝自社条件 × AI適性）

### AI的観点

- 自社データは**AIに学習／推論させる価値**があるか
    
- AI前処理・後処理を含めて**運用できるか**
    

### 失敗例

- データが少ない／汚い
    
- AI前提で業務フローが壊れる
    

👉 _AIはデータ文化の鏡_

---

## ④ 将（意思決定者｜AIの判断を誰が引き受けるか）

### AI的観点

- **AIの出力にNOと言える人**は誰か
    
- 誤答時の責任は人が持つ設計か
    

### 失敗例

- 「AIが言ったから」で決定
    
- 誰も止められない自動化
    

👉 _AI判断は必ず人が引き受ける_

---

## ⑤ 法（運用ルール｜AIを制御できるか）

### AI的観点

- Human-in-the-loopがあるか
    
- ログ・再現性・検証が可能か
    

### 失敗例

- 全自動・ブラックボックス
    
- コスト爆発・挙動不明
    

👉 _止められないAIは事故_

---

## AI × 五事

## エンジニア用・即席チェック（再定義）

**AI判断前に必ず自問**

- **なぜAIか？**（道）
    
- **今のAIで足りるか？**（天）
    
- **自社データ・現場に合うか？**（地）
    
- **AIの判断を誰が引き受ける？**（将）
    
- **間違えたら止められるか？**（法）
    

---

## 一文まとめ（AI時代の五事）

> **AI設計とは  
> 「どこまで機械に任せ、どこを人が責任持つか」を決めること**

---

ここで止めます。  
次に進めるなら：

- **この内容をレビュー用チェックシート化**
    
- **LLMプロダクト特化版**
    
- **vibe coding × AI × 五事**
    

どれにしますか？