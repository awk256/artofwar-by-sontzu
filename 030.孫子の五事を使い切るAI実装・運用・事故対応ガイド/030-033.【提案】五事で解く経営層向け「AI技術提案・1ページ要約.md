
# 結論

本提案の採否は、技術の優劣ではなく **「経営責任を負える統治（ガバナンス）が確立されているか」** で判断します。以下の「五事」の整合性が取れない案件は、将来的に経営リスクを招くため、現時点での導入を推奨しません。

# AI導入可否の5大判断基準（五事チェック）

#### 1. 【道】目的は明確か（Why）

* **論点：** AIによって「売上・コスト・リスク」のどれが、どう変わるのか。
* **判断の閾値：**
	* **可：** 「◯◯業務の時間を30%削減する」等、目的が数値で定義されている。
	* **否：** 「他社がやっている」「AIを使えば何かが変わる」という漠然とした期待。


### 2. 【将】責任者は誰か（Who）

* **論点：** AIの誤判断や事故が起きた際、最終的な責任を負い、システムを止める決断を下せる人間は誰か。
* **判断の閾値：**
	* **可：** 担当役員または現場責任者に、明確な「停止権限」が付与されている。
	* **否：** 「AIが判断したことなので」という、責任の所在が曖昧な設計。

### 3. 【天】今やる理由はあるか（When）

* **論点：** 労働環境、法規制、競合他社の動向など、今投資すべき外部環境が整っているか。
* **判断の閾値：**
	* **可：** 今導入しなければ、人手不足の深刻化や競争優位の喪失を招く合理的理由がある。
	* **再検討：** 技術が未成熟、あるいはコストが見合わず、先送りしても大きな損失がない。

### 4. 【地】自社に合っているか（Fit）

* **論点：** AIの燃料となる「データ」は質・量ともに十分か。現場の社員が拒絶せず活用できるか。
* **判断の閾値：**
	* **可：** データ基盤が整備されており、現場の運用フローにAIが自然に組み込まれる。
	* **否：** データが散逸しており、現場に過度な入力負担を強いる設計（PoCで終わる懸念）。

### 5. 【法】安全に運用できるか（Operate）

* **論点：** AIの判断を人間がチェックする仕組みはあるか。万が一の際の被害を最小化できるか。
* **判断の閾値：**
	* **可：** 人間が最終確認を行う（Human-in-the-loop）プロセスが標準化されている。
	* **否：** 全自動でプロセスがブラックボックス化しており、外部から修正や停止ができない。

>[020-032.Human-in-the-loop（HITL）：将の介在設計](../020.孫子の五事で設計するAI意思決定とガバナンス原則/020-032.Human-in-the-loop（HITL）：将の介在設計.md)

# 経営判断のための「最終確認3問」

決裁のハンコを押す前に、以下の3点を確認してください。

1. **AIが間違えたら、ビジネスやブランドにどれほどのダメージがありますか？**
2. **そのダメージを最小限にするため、人間が即座に介入して止められますか？**
3. **そのリスクを考慮しても、なお、将来的なリターンが勝りますか？**

# 経営判断の一文要約

> **AI導入とは、「便利なツール選び」ではなく、**
> **「責任を取れる自動化を、どこまで許容するか」を決める経営判断である。**

---

**次の一歩として、**
この要約をベースに、経営会議で反対意見が出た際の切り返しや、現場を納得させるための具体的な言葉選びを整理した [030-033.現場説明用トークスクリプト：孫子の言葉で伝えるAI活用] を作成しましょうか？